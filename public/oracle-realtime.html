<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Oracle Voice Chat</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      margin: 0;
      padding: 2rem;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    
    .container {
      max-width: 800px;
      width: 100%;
      background: white;
      border-radius: 20px;
      box-shadow: 0 20px 40px rgba(0,0,0,0.1);
      overflow: hidden;
    }
    
    .header {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 2rem;
      text-align: center;
    }
    
    .header h1 {
      margin: 0;
      font-size: 2.5rem;
      font-weight: 300;
    }
    
    .header p {
      margin: 0.5rem 0 0 0;
      opacity: 0.9;
      font-size: 1.1rem;
    }
    
    .controls {
      padding: 2rem;
      text-align: center;
      border-bottom: 1px solid #eee;
    }
    
    #mic {
      font-size: 1.5rem;
      padding: 1rem 2rem;
      border: none;
      border-radius: 50px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    }
    
    #mic:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
    }
    
    #mic.recording {
      background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
      animation: pulse 1.5s infinite;
    }
    
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.05); }
      100% { transform: scale(1); }
    }
    
    .status {
      margin-top: 1rem;
      padding: 0.5rem 1rem;
      border-radius: 25px;
      font-size: 0.9rem;
      min-height: 1.2rem;
    }
    
    .status.connected {
      background: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }
    
    .status.disconnected {
      background: #f8d7da;
      color: #721c24;
      border: 1px solid #f5c6cb;
    }
    
    .status.recording {
      background: #fff3cd;
      color: #856404;
      border: 1px solid #ffeaa7;
    }
    
    #chatLog {
      max-height: 400px;
      overflow-y: auto;
      padding: 1rem 2rem;
      min-height: 200px;
    }
    
    .message {
      margin: 1rem 0;
      padding: 0.75rem 1rem;
      border-radius: 15px;
      max-width: 80%;
      word-wrap: break-word;
    }
    
    .you {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      margin-left: auto;
      text-align: right;
    }
    
    .bot {
      background: #f8f9fa;
      color: #333;
      border: 1px solid #e9ecef;
      margin-right: auto;
    }
    
    .message-content {
      font-size: 1rem;
      line-height: 1.4;
    }
    
    .message-meta {
      font-size: 0.8rem;
      opacity: 0.7;
      margin-top: 0.25rem;
    }
    
    .api-key-section {
      padding: 1rem 2rem;
      background: #f8f9fa;
      border-top: 1px solid #eee;
    }
    
    .api-key-section input {
      width: 100%;
      padding: 0.75rem;
      border: 1px solid #ddd;
      border-radius: 8px;
      font-size: 1rem;
      margin-top: 0.5rem;
    }
    
    .api-key-section label {
      font-weight: 500;
      color: #333;
    }
    
    .warning {
      background: #fff3cd;
      color: #856404;
      padding: 1rem;
      border-radius: 8px;
      margin-top: 1rem;
      font-size: 0.9rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>üß† Oracle Voice Chat</h1>
      <p>Real-time voice conversation with OpenAI's Realtime API</p>
    </div>
    
    <div class="controls">
      <button id="mic">üé§ Start Conversation</button>
      <div id="status" class="status disconnected">Disconnected - Enter API key to begin</div>
    </div>
    
    <div id="chatLog"></div>
    
    <div class="api-key-section">
      <label for="apiKey">OpenAI API Key:</label>
      <input 
        type="password" 
        id="apiKey" 
        placeholder="Enter your OpenAI API key (sk-...)"
        value=""
      />
      <div class="warning">
        ‚ö†Ô∏è Your API key is stored locally and never sent to any server except OpenAI's official API.
      </div>
    </div>
  </div>

  <script>
    // === Global Variables ===
    let socket = null;
    let sessionId = null;
    let mediaRecorder = null;
    let audioStream = null;
    let recording = false;
    let apiKey = localStorage.getItem('openai-api-key') || '';
    
    // === DOM Elements ===
    const micBtn = document.getElementById('mic');
    const statusDiv = document.getElementById('status');
    const chatLog = document.getElementById('chatLog');
    const apiKeyInput = document.getElementById('apiKey');
    
    // === Initialize ===
    document.addEventListener('DOMContentLoaded', () => {
      apiKeyInput.value = apiKey;
      apiKeyInput.addEventListener('change', (e) => {
        apiKey = e.target.value;
        localStorage.setItem('openai-api-key', apiKey);
        updateStatus();
      });
      updateStatus();
    });
    
    // === Status Management ===
    function updateStatus(message = null) {
      if (message) {
        statusDiv.textContent = message;
        return;
      }
      
      if (!apiKey) {
        statusDiv.textContent = 'Disconnected - Enter API key to begin';
        statusDiv.className = 'status disconnected';
      } else if (socket && socket.readyState === WebSocket.OPEN) {
        if (recording) {
          statusDiv.textContent = 'üéôÔ∏è Recording... Speak now';
          statusDiv.className = 'status recording';
        } else {
          statusDiv.textContent = '‚úÖ Connected - Ready to chat';
          statusDiv.className = 'status connected';
        }
      } else {
        statusDiv.textContent = 'Disconnected - Click to connect';
        statusDiv.className = 'status disconnected';
      }
    }
    
    // === WebSocket Setup ===
    function connectWebSocket() {
      if (!apiKey) {
        alert('Please enter your OpenAI API key first');
        return false;
      }
      
      updateStatus('Connecting to OpenAI...');
      
      socket = new WebSocket("wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01", [
        'realtime', `Bearer.${apiKey}`
      ]);
      
      socket.onopen = () => {
        updateStatus('Connected! Initializing session...');
        
        // Send session configuration
        socket.send(JSON.stringify({
          type: 'session.update',
          session: {
            modalities: ['text', 'audio'],
            instructions: 'You are Oracle, a helpful AI assistant. Keep responses concise and conversational.',
            voice: 'alloy',
            input_audio_format: 'pcm16',
            output_audio_format: 'pcm16',
            input_audio_transcription: {
              model: 'whisper-1'
            }
          }
        }));
      };
      
      socket.onmessage = async (event) => {
        const message = JSON.parse(event.data);
        console.log('Received:', message.type, message);
        
        switch (message.type) {
          case 'session.created':
            sessionId = message.session.id;
            updateStatus();
            break;
            
          case 'input_audio_buffer.speech_started':
            updateStatus('üé§ Speech detected...');
            break;
            
          case 'input_audio_buffer.speech_stopped':
            updateStatus('ü§î Processing...');
            break;
            
          case 'conversation.item.input_audio_transcription.completed':
            if (message.transcript) {
              appendMessage('you', message.transcript);
            }
            break;
            
          case 'response.audio.delta':
            if (message.delta) {
              // Play audio chunk
              playAudioChunk(message.delta);
            }
            break;
            
          case 'response.text.delta':
            if (message.delta) {
              updateBotMessage(message.delta);
            }
            break;
            
          case 'response.done':
            updateStatus();
            break;
            
          case 'error':
            console.error('WebSocket error:', message);
            updateStatus(`Error: ${message.error?.message || 'Unknown error'}`);
            break;
        }
      };
      
      socket.onclose = () => {
        updateStatus('Disconnected');
        sessionId = null;
      };
      
      socket.onerror = (error) => {
        console.error('WebSocket error:', error);
        updateStatus('Connection error - Check your API key');
      };
      
      return true;
    }
    
    // === Audio Management ===
    async function startRecording() {
      try {
        audioStream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          } 
        });
        
        // Create MediaRecorder for PCM16 audio
        mediaRecorder = new MediaRecorder(audioStream, {
          mimeType: 'audio/webm;codecs=opus'
        });
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
            // Convert to base64 and send
            const reader = new FileReader();
            reader.onload = () => {
              const base64 = reader.result.split(',')[1];
              socket.send(JSON.stringify({
                type: 'input_audio_buffer.append',
                audio: base64
              }));
            };
            reader.readAsDataURL(event.data);
          }
        };
        
        mediaRecorder.start(100); // Send chunks every 100ms
        recording = true;
        updateStatus();
        
      } catch (error) {
        console.error('Error starting recording:', error);
        updateStatus('Microphone access denied');
      }
    }
    
    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
        audioStream = null;
      }
      
      if (socket && socket.readyState === WebSocket.OPEN) {
        // Commit the audio buffer
        socket.send(JSON.stringify({
          type: 'input_audio_buffer.commit'
        }));
        
        // Request response
        socket.send(JSON.stringify({
          type: 'response.create',
          response: {
            modalities: ['text', 'audio']
          }
        }));
      }
      
      recording = false;
      updateStatus();
    }
    
    // === Audio Playback ===
    let audioContext = null;
    let audioQueue = [];
    let isPlaying = false;
    
    async function initAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
      }
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
    }
    
    async function playAudioChunk(base64Audio) {
      await initAudioContext();
      
      try {
        const audioData = atob(base64Audio);
        const arrayBuffer = new ArrayBuffer(audioData.length);
        const view = new Uint8Array(arrayBuffer);
        
        for (let i = 0; i < audioData.length; i++) {
          view[i] = audioData.charCodeAt(i);
        }
        
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        audioQueue.push(audioBuffer);
        
        if (!isPlaying) {
          playNextAudio();
        }
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    }
    
    function playNextAudio() {
      if (audioQueue.length === 0) {
        isPlaying = false;
        return;
      }
      
      isPlaying = true;
      const audioBuffer = audioQueue.shift();
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      
      source.onended = () => {
        playNextAudio();
      };
      
      source.start();
    }
    
    // === Chat Interface ===
    function appendMessage(sender, text, isUpdating = false) {
      const messageClass = sender === 'you' ? 'you' : 'bot';
      
      if (isUpdating && chatLog.lastElementChild?.classList.contains(messageClass)) {
        // Update existing message
        const contentDiv = chatLog.lastElementChild.querySelector('.message-content');
        contentDiv.textContent = text;
      } else {
        // Create new message
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${messageClass}`;
        
        const contentDiv = document.createElement('div');
        contentDiv.className = 'message-content';
        contentDiv.textContent = text;
        
        const metaDiv = document.createElement('div');
        metaDiv.className = 'message-meta';
        metaDiv.textContent = new Date().toLocaleTimeString();
        
        messageDiv.appendChild(contentDiv);
        messageDiv.appendChild(metaDiv);
        chatLog.appendChild(messageDiv);
        
        // Scroll to bottom
        chatLog.scrollTop = chatLog.scrollHeight;
      }
    }
    
    let currentBotMessage = '';
    function updateBotMessage(delta) {
      currentBotMessage += delta;
      appendMessage('bot', currentBotMessage, true);
    }
    
    // === Main Control ===
    micBtn.onclick = async () => {
      if (!socket || socket.readyState !== WebSocket.OPEN) {
        if (connectWebSocket()) {
          // Wait for connection before allowing recording
          setTimeout(() => {
            if (socket && socket.readyState === WebSocket.OPEN) {
              micBtn.textContent = 'üé§ Start Recording';
            }
          }, 2000);
        }
        return;
      }
      
      if (!recording) {
        await startRecording();
        micBtn.textContent = '‚ñ† Stop Recording';
        micBtn.classList.add('recording');
        currentBotMessage = ''; // Reset bot message
      } else {
        stopRecording();
        micBtn.textContent = 'üé§ Start Recording';
        micBtn.classList.remove('recording');
      }
    };
    
    // === Cleanup ===
    window.addEventListener('beforeunload', () => {
      if (socket) {
        socket.close();
      }
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
      }
    });
  </script>
</body>
</html> 